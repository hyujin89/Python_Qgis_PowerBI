{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "executionInfo": {
     "elapsed": 17189,
     "status": "ok",
     "timestamp": 1738323346196,
     "user": {
      "displayName": "chioh song",
      "userId": "05482793768581925652"
     },
     "user_tz": -540
    },
    "id": "eej-wb9pN3tY"
   },
   "source": [
    "# Attention\n",
    "**\"프리트레인드 모델\" (Pretrained model)**은 이미 대규모 데이터셋을 사용하여 사전 학습된 모델을 의미. 즉, 이 모델은 특정 작업을 수행하기 전에 일반적인 언어나 데이터를 학습한 상태"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WAsSiQpBTHt2"
   },
   "source": [
    "### 데이터 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 395,
     "status": "ok",
     "timestamp": 1738323432257,
     "user": {
      "displayName": "chioh song",
      "userId": "05482793768581925652"
     },
     "user_tz": -540
    },
    "id": "cvh-450AN5KT",
    "outputId": "8fd827d6-33a0-43bf-cded-df56d937b115"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'나는': 0, '학교에': 1, '가고': 2, '있다': 3}\n",
      "{0: '나는', 1: '학교에', 2: '가고', 3: '있다'}\n"
     ]
    }
   ],
   "source": [
    "# 단어 시퀀스 데이터 준비\n",
    "words = ['나는', '학교에', '가고', '있다']\n",
    "word_to_idx = {word: idx for idx, word in enumerate(words)}\n",
    "idx_to_word = {idx: word for word, idx in word_to_idx.items()}\n",
    "\n",
    "print(word_to_idx)\n",
    "print(idx_to_word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5ZvisQzkTHt3"
   },
   "source": [
    "### 데이터 임베딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hi-aEeX7J9ll"
   },
   "outputs": [],
   "source": [
    "아산병원\n",
    "진료차트(자연어) -> 임베딩 -> 진료차트를 보고 이 사람이 1년이 내에 사망?생존?\n",
    "\n",
    "이 / 환자/ 는 / 노란 / 콧물\n",
    "헤모글로빈 / 수치 / 낮음\n",
    "* 토크나이징 -> 토큰화 -> 단어 개수 몇개인가? -> vocab_size  . 단어를 쪼개줌\n",
    "\n",
    "공백(어느정도의 스페이스)\n",
    "여러개의 공백 -> 하나의 공백으로 교체/개행 (엔터, 스페이스 등 공백 )\n",
    "\n",
    "구글이 만든 모델을 가져온다 -> 사전에 학습된 모델을 가져온다 -> 프리트레인드 모델(CNN과 연결)\n",
    "프리트레인드 모델 <- 나의 데이터를 추가적으로 쬬-끔 학습시켜줍니다 <- 나의 목적에 맞게 튜닝\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 323,
     "status": "ok",
     "timestamp": 1738324248528,
     "user": {
      "displayName": "chioh song",
      "userId": "05482793768581925652"
     },
     "user_tz": -540
    },
    "id": "k-dML2OtN7_p",
    "outputId": "1c745f33-e8c2-4c76-d17c-58d5c2b1db52"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.core.embedding.Embedding at 0x7f9734524790>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 임베딩 차원 설정\n",
    "# embedding_dim: 각 단어를 표현하는 벡터의 차원 수 (여기서는 5차원으로 설정, 3차원은 x,y,z축이며, 5차원은 그래프로 표현자체는 어려움, 차원을 높인다고 좋은건 아님, 차원의 저주 등이 존재하며)\n",
    "embedding_dim = 5\n",
    "\n",
    "# vocab_size: 어휘 사전의 크기 (총 단어의 개수)\n",
    "# words 리스트의 길이를 계산하여 설정 (여기서는 4개: '나는', '학교에', '가고', '있다')\n",
    "vocab_size = len(words) # 4\n",
    "\n",
    "# 임베딩 레이어 생성\n",
    "# tf.keras.layers.Embedding: 정수 인덱스를 고정된 크기의 밀집 벡터로 변환하는 레이어\n",
    "# 여기서는 4개의 단어('나는', '학교에', '가고', '있다')를 각각 5차원의 벡터로 변환하는 임베딩 레이어를 사용\n",
    "# 즉, 4x5 크기의 임베딩 행렬이 생성됨\n",
    "# 입력: vocab_size (어휘 크기)\n",
    "# 출력: embedding_dim (임베딩 차원)\n",
    "# 결과적으로 vocab_size x embedding_dim 크기의 임베딩 행렬이 생성됨\n",
    "embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim) # 4, 5\n",
    "embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5P4FrW2RTHt3"
   },
   "source": [
    "### 입력 시퀀스 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 352,
     "status": "ok",
     "timestamp": 1738324249895,
     "user": {
      "displayName": "chioh song",
      "userId": "05482793768581925652"
     },
     "user_tz": -540
    },
    "id": "a_5mHDFCOBkz",
    "outputId": "a6ff48e5-7f7a-41d4-aab4-15d530727472"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 1, 2, 3], [1, 2, 3, 0]]\n",
      "\n",
      "tf.Tensor(\n",
      "[[0 1 2 3]\n",
      " [1 2 3 0]], shape=(2, 4), dtype=int32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-01 22:45:08.999598: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# 입력 시퀀스 생성 (배치 크기 = 2) # 배치 에포크 이터레이션 (데이터가 크면 나눠서 진행해준다)\n",
    "# 두 개의 문장을 생성:\n",
    "# 1) \"나는 학교에 가고 있다\"\n",
    "# 2) \"학교에 가고 있다 나는\"\n",
    "# word_to_idx를 사용하여 각 단어를 정수 인덱스로 변환\n",
    "input_sequence = [\n",
    "    [word_to_idx['나는'], word_to_idx['학교에'], word_to_idx['가고'], word_to_idx['있다']],\n",
    "    [word_to_idx['학교에'], word_to_idx['가고'], word_to_idx['있다'], word_to_idx['나는']]\n",
    "    ]\n",
    "# 생성된 정수 시퀀스 출력\n",
    "print(input_sequence)\n",
    "print()\n",
    "\n",
    "\n",
    "\n",
    "# input_sequence를 텐서플로우 상수 텐서로 변환\n",
    "# 이는 나중에 임베딩 레이어의 입력으로 사용됨\n",
    "input_sequence_ = tf.constant(input_sequence)\n",
    "# 텐서로 변환된 시퀀스 출력\n",
    "print(input_sequence_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R1TT0caZTHt3"
   },
   "source": [
    "### 입력 시퀀스를 임베딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 348,
     "status": "ok",
     "timestamp": 1738324259077,
     "user": {
      "displayName": "chioh song",
      "userId": "05482793768581925652"
     },
     "user_tz": -540
    },
    "id": "NMbau2SuOEy_",
    "outputId": "3543c1c8-38ce-4d42-b1a9-2ef1ffa545c3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 4, 5), dtype=float32, numpy=\n",
       "array([[[-0.0294992 ,  0.00560477, -0.02485607, -0.01098778,\n",
       "         -0.0134889 ],\n",
       "        [ 0.00803609, -0.04116616, -0.04100607, -0.03225907,\n",
       "         -0.02941861],\n",
       "        [-0.01771401, -0.00604271, -0.01815657,  0.02957096,\n",
       "          0.02016914],\n",
       "        [-0.01247771,  0.01471099,  0.02071761,  0.01716476,\n",
       "         -0.02348535]],\n",
       "\n",
       "       [[ 0.00803609, -0.04116616, -0.04100607, -0.03225907,\n",
       "         -0.02941861],\n",
       "        [-0.01771401, -0.00604271, -0.01815657,  0.02957096,\n",
       "          0.02016914],\n",
       "        [-0.01247771,  0.01471099,  0.02071761,  0.01716476,\n",
       "         -0.02348535],\n",
       "        [-0.0294992 ,  0.00560477, -0.02485607, -0.01098778,\n",
       "         -0.0134889 ]]], dtype=float32)>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 임베딩 적용\n",
    "embedded_sequence = embedding(input_sequence_)  # shape: (2, 4, 5)\n",
    "embedded_sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wGPY83QcTHt3"
   },
   "source": [
    "### 쿼리 벡터 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 328,
     "status": "ok",
     "timestamp": 1738324329967,
     "user": {
      "displayName": "chioh song",
      "userId": "05482793768581925652"
     },
     "user_tz": -540
    },
    "id": "4fRnBNMkOGOv",
    "outputId": "cb9c51af-86f3-4f60-d180-8ed6dd799b08"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 5), dtype=float32, numpy=\n",
       "array([[-0.0294992 ,  0.00560477, -0.02485607, -0.01098778, -0.0134889 ],\n",
       "       [ 0.00803609, -0.04116616, -0.04100607, -0.03225907, -0.02941861]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 쿼리 벡터 생성 (예시로 첫 번째 단어의 임베딩을 쿼리로 사용)\n",
    "# 첫번째 문장: '나는'의 임베딩 벡터 [0.01159065, 0.02614441, 0.01953292, 0.0170218, 0.02222321]\n",
    "# 두번째 문장: '학교에'의 임베딩 벡터 [0.04224105, -0.01704571, 0.03613384, 0.00597052, 0.02944158]\n",
    "query = embedded_sequence[:, 0, :]  # shape: (2, 5)\n",
    "query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RCLsiXyUTHt3"
   },
   "source": [
    "### Attention 레이어 생성\n",
    "\n",
    "- 사용자 정의 레이어 생성\n",
    "- 구조 참고: https://www.tensorflow.org/tutorials/customization/custom_layers#implementing_custom_layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "executionInfo": {
     "elapsed": 344,
     "status": "ok",
     "timestamp": 1738326175964,
     "user": {
      "displayName": "chioh song",
      "userId": "05482793768581925652"
     },
     "user_tz": -540
    },
    "id": "8PKOGno0OAWZ"
   },
   "outputs": [],
   "source": [
    "# Attention 학습 방법\n",
    "# 1. Query, Key, Value 벡터 준비\n",
    "#    - Query: 현재 디코더의 은닉 상태 (찾고자 하는 정보)\n",
    "#    - Key: 인코더의 은닉 상태들 (참조할 정보)\n",
    "#    - Value: 실제 입력 시퀀스의 정보\n",
    "\n",
    "# 2. Attention Score 계산\n",
    "#    - Query와 Key 사이의 유사도를 내적으로 계산\n",
    "#    - 내적값이 클수록 두 벡터가 유사하며 해당 위치의 정보가 중요\n",
    "\n",
    "# 3. Attention Weight 계산\n",
    "#    - Score에 Softmax 적용하여 확률 분포로 변환\n",
    "#    - 모든 가중치의 합이 1이 되도록 정규화\n",
    "\n",
    "# 4. Context Vector 생성\n",
    "#    - Attention Weight와 Value를 가중합하여 최종 Context Vector 생성\n",
    "#    - 중요한 정보가 강조된 표현을 얻음\n",
    "\n",
    "# SimpleAttention 클래스는 tf.keras.layers.Layer를 상속받아 커스텀 레이어를 구현합니다.\n",
    "# tf.keras.layers.Layer는 모든 Keras 레이어의 기본 클래스입니다.\n",
    "# super().__init__()을 호출하여 부모 클래스의 초기화 메서드를 실행합니다.\n",
    "class SimpleAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, units):\n",
    "        super(SimpleAttention, self).__init__()\n",
    "\n",
    "        # units 인자는 Attention 메커니즘에서 사용할 은닉층의 크기를 지정합니다.\n",
    "        # 이 값은 Query와 Key를 동일한 차원으로 변환할 때 사용됩니다.\n",
    "\n",
    "        # 1단계: Query와 Key를 동일한 차원(units)으로 변환하기 위한 가중치 행렬 정의\n",
    "        # Dense 레이어의 출력 차원이 units가 됩니다.\n",
    "        self.W1 = tf.keras.layers.Dense(units)\n",
    "\n",
    "        # Attention score를 1차원으로 변환하기 위한 가중치 행렬\n",
    "        # Attention score를 1차원으로 변환하는 이유:\n",
    "        # 1. 각 시점(단어)마다 하나의 중요도 점수가 필요함\n",
    "        # 2. softmax 함수에 입력으로 사용하기 위해 스칼라 값 필요\n",
    "        # 3. attention weight를 계산할 때 각 단어별로 하나의 가중치가 필요하기 때문\n",
    "        # 최종적으로 각 시점에 대한 하나의 점수를 얻기 위해 1차원으로 압축\n",
    "        self.W2 = tf.keras.layers.Dense(1)\n",
    "\n",
    "    # call 메서드는 레이어가 호출될 때 실행되는 메서드입니다.\n",
    "    # tf.keras.layers.Layer를 상속받은 클래스에서 반드시 구현해야 하는 메서드이며,\n",
    "    # 실제 레이어의 연산을 정의하는 부분입니다.\n",
    "    # 입력:\n",
    "    # - query: 현재 디코더의 은닉 상태 (찾고자 하는 정보)\n",
    "    # - values: 인코더의 은닉 상태들 (참조할 정보이자 실제 입력 시퀀스의 정보)\n",
    "    def call(self, query, values):\n",
    "        # 1단계: Query 벡터 준비 - 시간 축 추가로 차원 확장\n",
    "        query_with_time_axis = tf.expand_dims(query, 1)\n",
    "        \n",
    "#         return query_with_time_axis\n",
    "        # 2단계: Attention Score 계산\n",
    "        # - Query와 Key(values)를 units 차원으로 변환 후 유사도를 내적을 활용하여 계산\n",
    "        # - 내적 후 tanh 활성화 함수로 비선형성 추가\n",
    "        score = self.W2(tf.nn.tanh(self.W1(query_with_time_axis) * self.W1(values)))\n",
    "\n",
    "        # # 3단계: Attention Weight 계산\n",
    "        # # - softmax로 정규화하여 모든 가중치 합이 1이 되도록 함\n",
    "        attention_weights = tf.nn.softmax(score, axis=1)\n",
    "\n",
    "        # # 4단계: Context Vector 계산\n",
    "        # # - attention weight와 value를 곱하여 중요 정보 강조\n",
    "        context_vector = attention_weights * values\n",
    "        # # - 가중합을 통해 최종 context vector 생성\n",
    "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "\n",
    "        return context_vector, attention_weights\n",
    "\n",
    "# embedding_dim을 units로 사용하여 Query와 Key의 차원을 맞춤\n",
    "# Query와 Key의 차원을 맞춰주는 이유:\n",
    "# 1. Attention Score 계산 시 내적 연산을 수행하기 위해서는 두 벡터의 차원이 동일해야 함\n",
    "# 2. SimpleAttention 클래스의 call() 메서드에서 self.W1을 통해 Query와 Key를 동일한 차원(units)으로 변환\n",
    "# 3. 이후 변환된 벡터들의 내적으로 유사도를 계산하여 Attention Score를 얻음\n",
    "# 따라서 embedding_dim을 units 파라미터로 사용하여 Query와 Key의 차원을 동일하게 맞춰줌\n",
    "attention_layer = SimpleAttention(embedding_dim) # 5\n",
    "context_vector, attention_weights = attention_layer(query, embedded_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q0Ig28y1TgC3"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 353,
     "status": "ok",
     "timestamp": 1738326183915,
     "user": {
      "displayName": "chioh song",
      "userId": "05482793768581925652"
     },
     "user_tz": -540
    },
    "id": "c2Yx38XJOqIm",
    "outputId": "15a0d8d6-064f-4b64-80fe-3e2f8b30f27f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "입력 문장:\n",
      "문장 1: 나는 학교에 가고 있다\n",
      "문장 2: 학교에 가고 있다 나는\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n입력 문장:\")\n",
    "for i in range(2):\n",
    "    print(f\"문장 {i+1}:\", \" \".join([idx_to_word[idx.numpy()] for idx in input_sequence_[i]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 327,
     "status": "ok",
     "timestamp": 1738326249723,
     "user": {
      "displayName": "chioh song",
      "userId": "05482793768581925652"
     },
     "user_tz": -540
    },
    "id": "7cZGNyMzUYkH",
    "outputId": "baa0162f-592c-4599-e3fb-b2efd3d33878"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       "array([[ 0.00803609, -0.04116616, -0.04100607, -0.03225907, -0.02941861]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 356,
     "status": "ok",
     "timestamp": 1738326341639,
     "user": {
      "displayName": "chioh song",
      "userId": "05482793768581925652"
     },
     "user_tz": -540
    },
    "id": "49RFv2EQOr-7",
    "outputId": "fa4df3e0-cddc-469e-e98e-ff575bea4cf7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Attention 가중치:\n",
      "\n",
      "문장 1의 각 단어에 대한 attention 가중치:\n",
      "나는: 0.250\n",
      "학교에: 0.250\n",
      "가고: 0.250\n",
      "있다: 0.250\n",
      "\n",
      "문장 2의 각 단어에 대한 attention 가중치:\n",
      "나는: 0.250\n",
      "학교에: 0.250\n",
      "가고: 0.250\n",
      "있다: 0.250\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nAttention 가중치:\")\n",
    "for i in range(2):\n",
    "    print(f\"\\n문장 {i+1}의 각 단어에 대한 attention 가중치:\")\n",
    "    for j, word in enumerate(words):\n",
    "        weight = attention_weights[i][j].numpy()[0]\n",
    "        print(f\"{idx_to_word[j]}: {weight:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Boa72iEjVBHa"
   },
   "source": [
    "---\n",
    "\n",
    "### tf.keras.layers.Attention을 사용한 더 간단한 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "executionInfo": {
     "elapsed": 331,
     "status": "ok",
     "timestamp": 1738326417918,
     "user": {
      "displayName": "chioh song",
      "userId": "05482793768581925652"
     },
     "user_tz": -540
    },
    "id": "ICLEsh4BVAmS"
   },
   "outputs": [],
   "source": [
    "# 자연어 처리를 위한 예시 문장 준비\n",
    "words = ['cat', 'saw', 'fish', 'in', 'the', 'pond', 'and', 'decided', 'to', 'catch']\n",
    "word_to_idx = {word: idx for idx, word in enumerate(words)}\n",
    "idx_to_word = {idx: word for idx, word in enumerate(words)}\n",
    "\n",
    "# 두 개의 영어 문장 생성\n",
    "input_sequence = tf.constant([\n",
    "    [0, 1, 2, 3, 4, 5, 6, 7, 8, 9],  # \"cat saw fish in the pond and decided to catch\" 10개의 단어\n",
    "    [2, 3, 4, 5, 6, 7, 8, 9, 9, 9]   # \"fish in the pond and decided to catch\" 8개 단어\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 351,
     "status": "ok",
     "timestamp": 1738326594635,
     "user": {
      "displayName": "chioh song",
      "userId": "05482793768581925652"
     },
     "user_tz": -540
    },
    "id": "xLdyW2hUVBHa",
    "outputId": "e9767f77-a644-4d56-e3fa-92a2b5c40fea"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 10), dtype=float32, numpy=\n",
       "array([[-0.8390877 ,  1.919225  ,  0.00363624, -0.66230583, -2.4693048 ,\n",
       "        -0.27012685, -1.1110951 ,  1.4539831 ,  0.09375298,  0.59442014],\n",
       "       [ 1.0056814 ,  0.26804754,  2.5898736 , -1.1057687 , -0.6461786 ,\n",
       "        -0.8894963 ,  1.7569269 ,  0.05415321,  0.35458943, -0.8559529 ]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# 단어 임베딩 차원 설정\n",
    "embedding_dim = 10\n",
    "\n",
    "# 문장에 단어 임베딩 레이어 생성 및 적용\n",
    "embedding_layer = tf.keras.layers.Embedding(len(words), embedding_dim)\n",
    "embedded_sequence = embedding_layer(input_sequence)\n",
    "\n",
    "# 문장 분석을 위한 Query 벡터 생성\n",
    "query = tf.random.normal([2, embedding_dim])  # batch size 2, embedding dimension 5\n",
    "query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 329,
     "status": "ok",
     "timestamp": 1738326637979,
     "user": {
      "displayName": "chioh song",
      "userId": "05482793768581925652"
     },
     "user_tz": -540
    },
    "id": "vfYsfxJBNr7t",
    "outputId": "38df3308-0ffe-47d2-bd7e-803c4f0e18b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "기본 Attention 레이어 출력:\n",
      "(2, 1, 10)\n",
      "tf.Tensor(\n",
      "[[[-0.00624432  0.01839223 -0.0094374   0.00470512 -0.01510459\n",
      "    0.00155678  0.01165645  0.01281288 -0.01358805  0.00321485]]\n",
      "\n",
      " [[ 0.00935854  0.01467576 -0.01652054 -0.00255084 -0.01317625\n",
      "    0.0145024   0.01836742  0.01648091 -0.00559907  0.00177507]]], shape=(2, 1, 10), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# tf.keras.layers.Attention을 사용한 더 간단한 구현\n",
    "attention = tf.keras.layers.Attention()\n",
    "\n",
    "# query와 value의 shape을 맞추기 위해 query 차원 확장\n",
    "query_with_time_axis = tf.expand_dims(query, 1)\n",
    "\n",
    "# Attention 계산\n",
    "attention_output = attention([query_with_time_axis, embedded_sequence])\n",
    "\n",
    "print(\"\\n기본 Attention 레이어 출력:\")\n",
    "print(attention_output.shape)\n",
    "print(attention_output)\n",
    "\n",
    "# 참고: tf.keras.layers.Attention은 내부적으로\n",
    "# Query, Key, Value에 대한 변환과 스케일링,\n",
    "# softmax를 통한 가중치 계산 등을 자동으로 처리합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 507
    },
    "executionInfo": {
     "elapsed": 2206,
     "status": "ok",
     "timestamp": 1738326683840,
     "user": {
      "displayName": "chioh song",
      "userId": "05482793768581925652"
     },
     "user_tz": -540
    },
    "id": "H-jIf5QpXjp3",
    "outputId": "a1e351ee-f5fc-46b2-ad01-3da2a8fca064"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 시각화를 위한 라이브러리 임포트\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Attention 가중치 계산\n",
    "attention_weights = tf.nn.softmax(attention_output, axis=-1)\n",
    "\n",
    "# 히트맵 그리기\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "# 첫 번째 문장의 Attention 시각화\n",
    "plt.subplot(2, 1, 1)\n",
    "sns.heatmap(attention_weights[0],\n",
    "            xticklabels=['cat', 'saw', 'fish', 'in', 'the', 'pond', 'and', 'decided', 'to', 'catch'],\n",
    "            yticklabels=['Sentence 1'],\n",
    "            annot=True)\n",
    "plt.title('Attention Weights of First Sentence')\n",
    "\n",
    "# 두 번째 문장의 Attention 시각화\n",
    "plt.subplot(2, 1, 2)\n",
    "sns.heatmap(attention_weights[1],\n",
    "            xticklabels=['fish', 'in', 'the', 'pond', 'and', 'decided', 'to', 'catch', 'catch', 'catch'],\n",
    "            yticklabels=['Sentence 2'],\n",
    "            annot=True)\n",
    "plt.title('Attention Weights of Second Sentence')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5_N6ql9PndM9"
   },
   "source": [
    "히트맵 시각화 결과 분석\n",
    "\n",
    "1. 두 문장의 Attention 가중치가 비슷한 패턴을 보이는 이유:\n",
    "   - 현재 구현된 기본 Attention 모델은 단순히 단어 임베딩 간의 유사도만을 계산\n",
    "   - 문맥적 정보나 위치 정보를 고려하지 않음\n",
    "   - 실제 자연어의 문맥적 의미를 충분히 반영하지 못함\n",
    "2. 개선 방안:\n",
    "   - Positional Encoding을 추가하여 단어의 위치 정보 반영\n",
    "   - Self-Attention 메커니즘 도입\n",
    "   - Multi-head Attention 사용으로 다양한 관점에서의 관계 파악\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "K14ii3nmVIYm"
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3319954619.py, line 8)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/var/folders/j5/k9v_p2y97k3299xzm4c48rg40000gn/T/ipykernel_9837/3319954619.py\"\u001b[0;36m, line \u001b[0;32m8\u001b[0m\n\u001b[0;31m    pip install sentencepiece\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#위치에 대한 정보를 제대로 파악하지 못하고 있음, 순서의 의미 Positional Encoding 반영해서 정확히 해줘야함\n",
    "\n",
    "#개선 방안:\n",
    "#Positional Encoding을 추가하여 단어의 위치 정보 반영\n",
    "#Self-Attention 메커니즘 도입\n",
    "#Multi-head Attention 사용으로 다양한 관점에서의 관계 파악"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 어떤 프리트레인드 모델을 사용할 계획\n",
    "\n",
    "#Transformer 기반(BERT, GPT, T5, etc.)\n",
    "#Vision 모델(ViT, CLIP, etc.)\n",
    "#Seq2Seq 모델(T5, BART, etc.)\n",
    "#다른 도메인 특화 모델(예: BioBERT, CodeBERT 등)\n",
    "\n",
    "#텍스트 분류\n",
    "#기계 번역\n",
    "#요약\n",
    "#질의응답(QA)\n",
    "#시계열 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ff6d2a157d049798acd5f012cd91c98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a603d6e0c1144d8cad71098d743aa08f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "368829dd1b744cfe8e132d5d067f44c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9c5a7a25b9c4ace8b561054ae26f600",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "586129c8c1df4d83be704eb3243d3f01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/892M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/j5/k9v_p2y97k3299xzm4c48rg40000gn/T/ipykernel_10464/2152471693.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"t5-base\"\u001b[0m \u001b[0;31m# 또는 \"t5-large\",\"t5-small\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mT5Tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_download\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mT5ForConditionalGeneration\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_download\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# 모델 선택\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   3035\u001b[0m                         \u001b[0;34m\"_commit_hash\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcommit_hash\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3036\u001b[0m                     }\n\u001b[0;32m-> 3037\u001b[0;31m                     \u001b[0mresolved_archive_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcached_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcached_file_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3039\u001b[0m                     \u001b[0;31m# Since we set _raise_exceptions_for_missing_entries=False, we don't get an exception but a None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    428\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m         \u001b[0;31m# Load from URL or cache if already cached\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m         resolved_file = hf_hub_download(\n\u001b[0m\u001b[1;32m    431\u001b[0m             \u001b[0mpath_or_repo_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    116\u001b[0m             \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmoothly_deprecate_use_auth_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhas_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhas_token\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_inner_fn\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36mhf_hub_download\u001b[0;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, local_dir_use_symlinks, user_agent, force_download, force_filename, proxies, etag_timeout, resume_download, token, local_files_only, legacy_cache_layout, endpoint)\u001b[0m\n\u001b[1;32m   1459\u001b[0m                     \u001b[0m_check_disk_space\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpected_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1461\u001b[0;31m             http_get(\n\u001b[0m\u001b[1;32m   1462\u001b[0m                 \u001b[0murl_to_download\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1463\u001b[0m                 \u001b[0mtemp_file\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36mhttp_get\u001b[0;34m(url, temp_file, proxies, resume_size, headers, expected_size, _nb_retries)\u001b[0m\n\u001b[1;32m    539\u001b[0m         \u001b[0mnew_resume_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresume_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter_content\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDOWNLOAD_CHUNK_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# filter out keep-alive new chunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m                     \u001b[0mprogress\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/requests/models.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m()\u001b[0m\n\u001b[1;32m    814\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"stream\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    815\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 816\u001b[0;31m                     \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    817\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mProtocolError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mChunkedEncodingError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/urllib3/response.py\u001b[0m in \u001b[0;36mstream\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m    574\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_fp_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 576\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecode_content\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    577\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/urllib3/response.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, amt, decode_content, cache_content)\u001b[0m\n\u001b[1;32m    517\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m                 \u001b[0mcache_content\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 519\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfp_closed\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34mb\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    520\u001b[0m                 if (\n\u001b[1;32m    521\u001b[0m                     \u001b[0mamt\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/http/client.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    460\u001b[0m             \u001b[0;31m# Amount is given, implement using readinto\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m             \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytearray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m             \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadinto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    463\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mmemoryview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtobytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/http/client.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    504\u001b[0m         \u001b[0;31m# connection, and the user is reading more bytes than will be provided\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m         \u001b[0;31m# (for example, reading in 1k chunks)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 506\u001b[0;31m         \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadinto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    507\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    508\u001b[0m             \u001b[0;31m# Ideally, we would raise IncompleteRead if the content-length\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    702\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 704\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    705\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1239\u001b[0m                   \u001b[0;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1240\u001b[0m                   self.__class__)\n\u001b[0;32m-> 1241\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1242\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1243\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1097\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1098\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1099\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1100\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1101\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "\n",
    "model_name = \"t5-base\" # 또는 \"t5-large\",\"t5-small\"\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_name, force_download=True)\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_name, force_download=True)\n",
    "\n",
    "# 모델 선택\n",
    "# model_name = \"t5-large\"  \n",
    "# tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "# model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
    "\n",
    "# 긴 입력 문장\n",
    "text = \"\"\"\n",
    "자연어 처리는 인공지능의 한 분야로, 컴퓨터가 인간의 언어를 이해하고 생성할 수 있도록 돕는다. \n",
    "최근에는 딥러닝 기반의 모델들이 등장하며 자연어 처리 성능이 크게 향상되었다. \n",
    "특히, 트랜스포머 기반의 모델들은 번역, 요약, 질의응답 등의 다양한 작업에서 뛰어난 성능을 보이고 있다. \n",
    "예를 들어, BERT와 GPT 같은 모델들은 특정한 자연어 처리 작업에서 기존 모델보다 훨씬 더 뛰어난 성능을 보인다. \n",
    "\"\"\"\n",
    "\n",
    "# 입력 변환\n",
    "input_text = \"summarize: \" + text\n",
    "inputs = tokenizer(input_text, return_tensors=\"pt\", max_length=1000, truncation=True, padding=\"longest\")\n",
    "\n",
    "# 요약 생성\n",
    "summary_ids = model.generate(**inputs, max_length=1000, min_length=30, num_beams=5, early_stopping=True)\n",
    "summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
    "\n",
    "print(\"요약 결과:\", summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델: t5-large\n",
      "토크나이저 vocab 크기: 32000\n"
     ]
    }
   ],
   "source": [
    "print(f\"모델: {model_name}\")\n",
    "print(f\"토크나이저 vocab 크기: {tokenizer.vocab_size}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized Input: [21603, 10, 3, 2, 3, 2, 3, 2, 3, 2, 3, 2, 6, 3, 2, 3, 2, 3, 2, 3, 2, 3, 2, 3, 2, 3, 2, 3, 2, 5, 3, 2, 3, 2, 3, 2, 3, 2, 3, 2, 3, 2, 3, 2, 3, 2, 3, 2, 3, 2, 5, 3, 2, 6, 3, 2, 3, 2, 3, 2, 3, 2, 6, 3, 2, 6, 3, 2, 3, 2, 3, 2, 3, 2, 3, 2, 3, 2, 3, 2, 3, 2, 5, 3, 2, 3, 2, 6, 272, 24203, 2, 350, 6383, 3, 2, 3, 2, 3, 2, 3, 2, 3, 2, 3, 2, 3, 2, 3, 2, 3, 2, 3, 2, 3, 2, 3, 2, 3, 2, 5, 1]\n"
     ]
    }
   ],
   "source": [
    "print(\"Tokenized Input:\", tokenizer.encode(input_text, truncation=True, max_length=512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "생성된 요약 토큰: tensor([[0, 3, 2, 3, 2, 3, 2, 3, 2, 3, 2, 3, 2, 3, 2, 3, 2, 3, 2, 3, 2, 3, 2, 3,\n",
      "         2, 3, 2, 3, 2, 3, 2, 3, 2, 3, 2, 3, 2, 3, 2, 3, 2, 3, 2, 3, 2, 5, 1]])\n",
      "디코딩된 요약: <pad> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>.</s>\n"
     ]
    }
   ],
   "source": [
    "print(\"생성된 요약 토큰:\", summary_ids)\n",
    "print(\"디코딩된 요약:\", tokenizer.decode(summary_ids[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트 요약 결과: quick brown fox jumps over lazy dog.\n"
     ]
    }
   ],
   "source": [
    "test_text = \"summarize: The quick brown fox jumps over the lazy dog.\"\n",
    "inputs = tokenizer(test_text, return_tensors=\"pt\", max_length=512, truncation=True)\n",
    "summary_ids = model.generate(**inputs, max_length=50, num_beams=5, early_stopping=True)\n",
    "summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "\n",
    "print(\"테스트 요약 결과:\", summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type mt5 to instantiate a model of type t5. This is not supported for all configurations of models and can yield errors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "요약 결과: 한 분 한분의 은혜에 대해 한글 요약: 20여 년 동안 문단생활을 해온 장문 작가\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "\n",
    "# ✅ 한글 지원 모델 사용\n",
    "model_name = \"google/mt5-small\"\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
    "\n",
    "# ✅ 긴 문장 테스트\n",
    "text = \"\"\"20여 년 동안 문단생활을 해온 장문 작가는 노동자 작가다. 오늘도 그는 인천 송도에 있는 세계문자박물관 건설 현장에서 비지땀을 흘리며 마음의 문자를 발굴해내고 있다. 매일 같이 자재를 들어 나르고 지시하며, 눈 깜짝하는 사이에 사고가 도사리고 있어 늘 긴장해야 하는 건설 현장에서 일하면서 언제 이 많은 분량의 글을 쓰며, 어떻게 이렇게 기발한 상상력으로 이런 소설을 써낼 수 있었는지가 놀랍다.\n",
    "\n",
    "장문 작가는 이미 시조시인으로 널리 알려진 분이다. 20여 년 동안 그는 여러 문학단체에서 활발히 문단 활동을 해오며 한국스토리문인협회가 주관한 스토리문학상(시조부문)을 수상하기도 했다. 그런 시조시인이 이렇게 소설을 잘 써 내리라고는 상상치 못했다. 장문 작가의 상상력은 가히 기발함을 넘어 뛰어나다고 말할 수 있다.\n",
    "\n",
    "장문 작가는 자서를 통해 “글을 쓰는 사람은 자신의 글을 끝까지 읽어주고 공감해준다면 그것은 행복이고 은혜다. 명예를 목적으로 할 필요도 없고, 더불어 행복하기에 글을 쓰는 이유다. 남들 다 은퇴한 나이에도 일하면서 소설을 쓴다는 것이 무모한 도전일 수 있지만, 그동안 필자의 시와 시조를 사랑해준 한 분 한 분의 은혜에 대해 1만분의 일이라도 갚을 길을 찾고, 언제 끝날지 모르는 코로나19 속 힘드신 분들에게 위로와 응원의 마음을 담아 이번 단편소설집 ‘끈’을 출간하게 됐다”고 책을 펴내는 마음을 피력했다.\n",
    "\"\"\"\"\"\n",
    "\n",
    "# ✅ 입력 데이터 변환 (prefix 추가)\n",
    "input_text = \"한글 요약: \" + text\n",
    "inputs = tokenizer(input_text, return_tensors=\"pt\", max_length=512, truncation=True, padding=\"longest\")\n",
    "\n",
    "# ✅ 요약 생성 (extra_id 방지 설정 추가)\n",
    "summary_ids = model.generate(\n",
    "    inputs.input_ids, \n",
    "    max_length=150, \n",
    "    min_length=30, \n",
    "    num_beams=5, \n",
    "    early_stopping=True, \n",
    "    no_repeat_ngram_size=3  # 반복되는 구절 방지\n",
    ")\n",
    "\n",
    "# ✅ 요약 결과 디코딩 후 불필요한 토큰 제거\n",
    "summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "summary = re.sub(r\"<extra_id_\\d+>\", \"\", summary).strip()  # 특수 토큰 제거\n",
    "summary = \" \".join(summary.split())  # 띄어쓰기 정리\n",
    "\n",
    "print(\"요약 결과:\", summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e5d55841b8c487f9fd78e461b8f0fef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4f411023a1649789eea0ddef88b2e3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d4cd62123574694b3890c4bfb917d32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1f691336f6946bbb9e3be2e74e21660",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3585dfc978194391947342b9378b33b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SequenceClassifierOutput(loss=None, logits=tensor([[0.0864, 0.4036]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "# Hugging Face에서 모델과 토크나이저 로드\n",
    "model_name = \"bert-base-uncased\"  # 예시로 BERT 모델 사용\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# 예시 텍스트 처리\n",
    "inputs = tokenizer(\"Hello, this is an example sentence.\", return_tensors=\"pt\")\n",
    "outputs = model(**inputs)\n",
    "\n",
    "print(outputs)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
